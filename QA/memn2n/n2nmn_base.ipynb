{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구현하려는 것\n",
    "# https://github.com/vinhkhuc/MemN2N-babi-python\n",
    "# https://github.com/nmhkahn/MemN2N-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "data_dir = glob.glob(os.getcwd() + '/data/')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!cd /home/hyungjunkim/Dropbox/repo/dl/MemN2N/scripts/data && \\  \n",
    "wget https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz && \\  \n",
    "tar xvf babi_tasks_1-20_v1-2.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datautils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/re.py:203: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "train_data = bAbIDataset(data_dir + 'tasks_1-20_v1-2/en/', task_id=1, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/re.py:203: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "test_data = bAbIDataset(data_dir + 'tasks_1-20_v1-2/en/', task_id=1, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_re = {value:key for key, value in train_data.word_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'back',\n",
       " 2: 'bathroom',\n",
       " 3: 'bedroom',\n",
       " 4: 'daniel',\n",
       " 5: 'garden',\n",
       " 6: 'hallway',\n",
       " 7: 'is',\n",
       " 8: 'john',\n",
       " 9: 'journeyed',\n",
       " 10: 'kitchen',\n",
       " 11: 'mary',\n",
       " 12: 'moved',\n",
       " 13: 'office',\n",
       " 14: 'sandra',\n",
       " 15: 'the',\n",
       " 16: 'to',\n",
       " 17: 'travelled',\n",
       " 18: 'went',\n",
       " 19: 'where'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 12 16 15  2 11]\n",
      "mary moved to the bathroom mary\n",
      "[ 8 18 16 15  6 10]\n",
      "john went to the hallway kitchen\n",
      "[0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0]\n",
      "\n",
      "where is mary\n",
      "bathroom\n"
     ]
    }
   ],
   "source": [
    "for x,y,z in train_data:\n",
    "    for idx in x:\n",
    "        print (idx)\n",
    "        print (\" \".join([word_re.get(int(i), '.') for i in idx if int(i) != 0]))\n",
    "    \n",
    "    print (\" \".join([word_re.get(int(i), '?') for i in y if int(i) != 0]))\n",
    "    print (word_re.get(int(z), '?'))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = train_data.data_story, train_data.data_query, train_data.data_answer\n",
    "inputs_test, queries_test, answers_test = test_data.data_story, test_data.data_query, test_data.data_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_encoding(sentences, emb_dim):\n",
    "    s_tmp = sentences.asnumpy()\n",
    "    n_row,n_col = np.shape(s_tmp)\n",
    "    for i in range(n_row):\n",
    "        for j in range(n_col):\n",
    "            s_tmp[i,j] = (1-j/n_col) - (n_row/emb_dim)*(1-2*j/n_col)    \n",
    "    return mx.nd.array(s_tmp, ctx).expand_dims(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-To-End Memory Network (N2NMN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i = 문장   \n",
    "j = 단어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs: $x_{i}$: 문장(context)  \n",
    "$q$: 질의  \n",
    "$target$: 답변(a word or words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img0](imgs/n2nmn_fig0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 메모리 벡터: 임베딩된 워드의 합을 문장으로 표기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$m_{i}={\\sum}_{j}Ax_{i,j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention $P_{i}$: 질의(q)와 가장 관련된 Senence(context) 확률로 나타냄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P_i=Softmax(uT {\\cdot} mi)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$o={\\sum}_{i}p_{i}c_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a=Softmax(W(o+u))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "internal state $u={\\sum}_{j}Bq_{j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습: A, C, B, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multi-layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adjacent: output embedding(o1 + u1)이 새로운 input embedding이 됨   \n",
    "Layer-wise (RNN-like): 모든 레이어가 A와 C를 공유함.  $uk^{+1} = Hu^{k}+o^{k}$, linear mapping H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 성능 올리기: 1. Senetence Representation, 2. Terporal Encoding, 3. Lerning time invariance by injection random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10, 6)\n",
      "(1000, 6)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print (np.shape(inputs_train))\n",
    "print (np.shape(queries_train))\n",
    "print (np.shape(answers_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, nd, init\n",
    "from mxnet.gluon import Block, nn\n",
    "\n",
    "\n",
    "class MemN2N(Block):\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super(MemN2N, self).__init__(**kwargs)\n",
    "\n",
    "        ## 고정\n",
    "        self.vocab_size = 29\n",
    "        \n",
    "        ## \n",
    "        self.init_std = 0.015\n",
    "        self.nhop = 3\n",
    "        self.emb_dim = 50\n",
    "\n",
    "        with self.name_scope():\n",
    "            \n",
    "            # Embedding A (메모리 벡터)\n",
    "            self.A = nn.Embedding(input_dim=self.vocab_size, \n",
    "                                  output_dim=self.emb_dim, \n",
    "                                  weight_initializer=init.Normal(self.init_std))\n",
    "             \n",
    "            # Embedding C (컨텍스트 벡터)\n",
    "            self.C = nn.Embedding(input_dim=self.vocab_size,\n",
    "                                  output_dim=self.emb_dim, \n",
    "                                  weight_initializer=init.Normal(self.init_std))\n",
    "            \n",
    "            # Embedding Q (쿼리 벡터)\n",
    "            self.B = nn.Embedding(input_dim=self.vocab_size, \n",
    "                                  output_dim=self.emb_dim, \n",
    "                                  weight_initializer=init.Normal(self.init_std))\n",
    "\n",
    "            # Final Predict \n",
    "            self.W = nn.Dense(self.vocab_size, weight_initializer=init.Normal(self.init_std))\n",
    "            \n",
    "    def forward(self, sentences, question):\n",
    "\n",
    "        hid = []\n",
    "        hid.append(question)\n",
    "        \n",
    "        # 16, 10, 7 , 20 > 16, 10, 20\n",
    "        m_i = self.A(sentences) #* position_encoding(sentences, self.emb_dim)\n",
    "        m_i = m_i.sum(axis=2)\n",
    "        \n",
    "        # 16, 10, 7 , 20 > 16, 10, 20\n",
    "        c_i = self.C(sentences)\n",
    "        c_i = c_i.sum(axis=2)\n",
    "            \n",
    "        for n in range(self.nhop):\n",
    "            \n",
    "            if n == 0:\n",
    "                #  16, 7, 20 > 16, 20\n",
    "                u = self.B(hid[-1])# * position_encoding(hid[-1], self.emb_dim)\n",
    "                u = u.sum(axis=1)\n",
    "            else:\n",
    "                u = hid[-1]\n",
    "\n",
    "            # [16, 1, 20] [16, 20, 10]  > [16, 1, 10]\n",
    "            m_out = nd.batch_dot(u.expand_dims(1), m_i.swapaxes(1,2))\n",
    "            P = nd.softmax(m_out, axis=2)\n",
    "            \n",
    "            #Cout = P * c_i\n",
    "            # [16, 1, 10] [16, 10, 20] > [16, 1, 20]\n",
    "            Cout = nd.batch_dot(P,  c_i)\n",
    "            # [16, 1, 20] > [16, 20]\n",
    "            o = Cout.sum(axis=(1))\n",
    "            \n",
    "            ## O + U [16, 20]\n",
    "            Dout = o + u\n",
    "            hid.append(Dout)\n",
    "           \n",
    "        z = self.W(hid[-1])\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainer, x_input, x_query, x_answers, batch_size):\n",
    "    softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    max_grad_norm=40\n",
    "    N = int(math.ceil(len(x_input) / batch_size))\n",
    "    cost = 0.0\n",
    "\n",
    "    for idx in range(N):\n",
    "        with autograd.record():\n",
    "            out = model(x_input, x_query)\n",
    "            loss = softmax_cross_entropy(out, x_answers)\n",
    "            loss.backward()\n",
    "            \n",
    "        grads = [i.grad() for i in model.collect_params().values()]\n",
    "        gluon.utils.clip_global_norm(grads, max_grad_norm)\n",
    "        trainer.step(batch_size)\n",
    "        cost += nd.sum(loss).asscalar()\n",
    "\n",
    "    return cost/N/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MemN2N(None)\n",
    "model.collect_params().initialize(mx.init.Xavier(),ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MemN2N(\n",
      "  (C): Embedding(29 -> 50, float32)\n",
      "  (W): Dense(50 -> 29, linear)\n",
      "  (A): Embedding(29 -> 50, float32)\n",
      "  (B): Embedding(29 -> 50, float32)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(model.collect_params(), 'adam', {'learning_rate': 0.01})\n",
    "log_loss = []\n",
    "log_perp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs  = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'perplexity': 6.03377192163973, 'learning_rate': 0.01}\n",
      "{'epoch': 1, 'perplexity': 5.575389677322674, 'learning_rate': 0.01}\n",
      "{'epoch': 2, 'perplexity': 5.550941548354227, 'learning_rate': 0.01}\n",
      "{'epoch': 3, 'perplexity': 5.175986634233491, 'learning_rate': 0.01}\n",
      "{'epoch': 4, 'perplexity': 5.54854993218375, 'learning_rate': 0.01}\n",
      "update learning rate from 0.010 to 0.007\n",
      "{'epoch': 5, 'perplexity': 3.4855251515202963, 'learning_rate': 0.006666666666666667}\n",
      "{'epoch': 6, 'perplexity': 2.2255794246030987, 'learning_rate': 0.006666666666666667}\n",
      "{'epoch': 7, 'perplexity': 1.7860665055961562, 'learning_rate': 0.006666666666666667}\n",
      "{'epoch': 8, 'perplexity': 1.846349267424668, 'learning_rate': 0.006666666666666667}\n",
      "update learning rate from 0.007 to 0.004\n",
      "{'epoch': 9, 'perplexity': 1.6745552927671736, 'learning_rate': 0.0044444444444444444}\n",
      "{'epoch': 10, 'perplexity': 1.5612030089214397, 'learning_rate': 0.0044444444444444444}\n",
      "{'epoch': 11, 'perplexity': 1.597875108695894, 'learning_rate': 0.0044444444444444444}\n",
      "update learning rate from 0.004 to 0.003\n",
      "{'epoch': 12, 'perplexity': 1.5909489202691296, 'learning_rate': 0.002962962962962963}\n",
      "{'epoch': 13, 'perplexity': 1.5612907156760842, 'learning_rate': 0.002962962962962963}\n",
      "{'epoch': 14, 'perplexity': 1.5231803843775276, 'learning_rate': 0.002962962962962963}\n",
      "{'epoch': 15, 'perplexity': 1.4832887009294833, 'learning_rate': 0.002962962962962963}\n",
      "{'epoch': 16, 'perplexity': 1.4792430200073579, 'learning_rate': 0.002962962962962963}\n",
      "{'epoch': 17, 'perplexity': 1.4714603218251097, 'learning_rate': 0.002962962962962963}\n",
      "{'epoch': 18, 'perplexity': 1.4436527916289064, 'learning_rate': 0.002962962962962963}\n",
      "{'epoch': 19, 'perplexity': 1.4474462634002774, 'learning_rate': 0.002962962962962963}\n",
      "update learning rate from 0.003 to 0.002\n",
      "{'epoch': 20, 'perplexity': 1.3862382953832872, 'learning_rate': 0.0019753086419753087}\n",
      "{'epoch': 21, 'perplexity': 1.326451616782325, 'learning_rate': 0.0019753086419753087}\n",
      "{'epoch': 22, 'perplexity': 1.3270287021677145, 'learning_rate': 0.0019753086419753087}\n",
      "update learning rate from 0.002 to 0.001\n",
      "{'epoch': 23, 'perplexity': 1.3255882567190465, 'learning_rate': 0.0013168724279835392}\n",
      "{'epoch': 24, 'perplexity': 1.3224198674154515, 'learning_rate': 0.0013168724279835392}\n",
      "{'epoch': 25, 'perplexity': 1.3175822653528206, 'learning_rate': 0.0013168724279835392}\n",
      "{'epoch': 26, 'perplexity': 1.3144967872237456, 'learning_rate': 0.0013168724279835392}\n",
      "{'epoch': 27, 'perplexity': 1.3129009422146596, 'learning_rate': 0.0013168724279835392}\n",
      "{'epoch': 28, 'perplexity': 1.311093401688517, 'learning_rate': 0.0013168724279835392}\n",
      "{'epoch': 29, 'perplexity': 1.3097338368704974, 'learning_rate': 0.0013168724279835392}\n",
      "{'epoch': 30, 'perplexity': 1.3096475765380093, 'learning_rate': 0.0013168724279835392}\n",
      "{'epoch': 31, 'perplexity': 1.3084581149054244, 'learning_rate': 0.0013168724279835392}\n",
      "{'epoch': 32, 'perplexity': 1.3073173042054764, 'learning_rate': 0.0013168724279835392}\n",
      "{'epoch': 33, 'perplexity': 1.3069368265994885, 'learning_rate': 0.0013168724279835392}\n",
      "{'epoch': 34, 'perplexity': 1.3063463649227904, 'learning_rate': 0.0013168724279835392}\n",
      "{'epoch': 35, 'perplexity': 1.305724182629361, 'learning_rate': 0.0013168724279835392}\n",
      "{'epoch': 36, 'perplexity': 1.3059705290356394, 'learning_rate': 0.0013168724279835392}\n",
      "update learning rate from 0.001 to 0.001\n",
      "{'epoch': 37, 'perplexity': 1.3057946181686708, 'learning_rate': 0.0008779149519890262}\n",
      "{'epoch': 38, 'perplexity': 1.3048467421237173, 'learning_rate': 0.0008779149519890262}\n",
      "{'epoch': 39, 'perplexity': 1.30458777731927, 'learning_rate': 0.0008779149519890262}\n",
      "{'epoch': 40, 'perplexity': 1.3044570312872108, 'learning_rate': 0.0008779149519890262}\n",
      "{'epoch': 41, 'perplexity': 1.3045180289203808, 'learning_rate': 0.0008779149519890262}\n",
      "update learning rate from 0.001 to 0.001\n",
      "{'epoch': 42, 'perplexity': 1.3029982149904247, 'learning_rate': 0.0005852766346593508}\n",
      "{'epoch': 43, 'perplexity': 1.3031196106426746, 'learning_rate': 0.0005852766346593508}\n",
      "update learning rate from 0.001 to 0.000\n",
      "{'epoch': 44, 'perplexity': 1.3021240033489516, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 45, 'perplexity': 1.3020700248776018, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 46, 'perplexity': 1.301871437513961, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 47, 'perplexity': 1.301729131322085, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 48, 'perplexity': 1.30146655749044, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 49, 'perplexity': 1.3012730648997715, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 50, 'perplexity': 1.3009993389009127, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 51, 'perplexity': 1.3007703281195142, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 52, 'perplexity': 1.300488219937225, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 53, 'perplexity': 1.3002294613937793, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 54, 'perplexity': 1.2999300757171797, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 55, 'perplexity': 1.2996384279375077, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 56, 'perplexity': 1.2993110267975614, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 57, 'perplexity': 1.2989825467541416, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 58, 'perplexity': 1.2986248132799219, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 59, 'perplexity': 1.298270428403496, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 60, 'perplexity': 1.297906392681981, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 61, 'perplexity': 1.2975564575716683, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 62, 'perplexity': 1.297203601350592, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 63, 'perplexity': 1.2968616628967593, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 64, 'perplexity': 1.2965145596423853, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 65, 'perplexity': 1.2961731891072563, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 66, 'perplexity': 1.2958249957077146, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 67, 'perplexity': 1.2954794825973381, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 68, 'perplexity': 1.295127268382383, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 69, 'perplexity': 1.2947763847216203, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 70, 'perplexity': 1.2944203111013737, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 71, 'perplexity': 1.294065646652984, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 72, 'perplexity': 1.293707725048426, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 73, 'perplexity': 1.2933516369588414, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 74, 'perplexity': 1.292994452319223, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 75, 'perplexity': 1.29263960069368, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 76, 'perplexity': 1.2922853471244906, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 77, 'perplexity': 1.29193415533979, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 78, 'perplexity': 1.2915847141596288, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 79, 'perplexity': 1.2912388308637892, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 80, 'perplexity': 1.2908954639084087, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 81, 'perplexity': 1.2905561113354667, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 82, 'perplexity': 1.2902191166100911, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 83, 'perplexity': 1.2898840550746309, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 84, 'perplexity': 1.2895516939010316, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 85, 'perplexity': 1.2892227994830125, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 86, 'perplexity': 1.288897676508607, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 87, 'perplexity': 1.2885762453614444, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 88, 'perplexity': 1.288258695285626, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 89, 'perplexity': 1.2879452537536682, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 90, 'perplexity': 1.2876356491827443, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 91, 'perplexity': 1.287329917207657, 'learning_rate': 0.0003901844231062339}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 92, 'perplexity': 1.2870280934614655, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 93, 'perplexity': 1.286730136881509, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 94, 'perplexity': 1.2864358914593927, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 95, 'perplexity': 1.2861455463311084, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 96, 'perplexity': 1.2858587539917306, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 97, 'perplexity': 1.285575397154238, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 98, 'perplexity': 1.2852955501850487, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 99, 'perplexity': 1.2850187129639299, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 100, 'perplexity': 1.2847449984373418, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 101, 'perplexity': 1.2844738304304255, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 102, 'perplexity': 1.2842050925383288, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 103, 'perplexity': 1.283938017972685, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 104, 'perplexity': 1.2836720127446022, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 105, 'perplexity': 1.2834059287575876, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 106, 'perplexity': 1.2831382938233333, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 107, 'perplexity': 1.282866929685753, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 108, 'perplexity': 1.2825885514563085, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 109, 'perplexity': 1.282299265739804, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 110, 'perplexity': 1.2819958132886489, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 111, 'perplexity': 1.2816792546095723, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 112, 'perplexity': 1.281362067627052, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 113, 'perplexity': 1.281070615091321, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 114, 'perplexity': 1.2808300152999794, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 115, 'perplexity': 1.2806443806466663, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 116, 'perplexity': 1.2804972203251552, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 117, 'perplexity': 1.2803672478617387, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 118, 'perplexity': 1.2802398258371974, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 119, 'perplexity': 1.2801077812378396, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 120, 'perplexity': 1.279966881285242, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 121, 'perplexity': 1.2798164042178657, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 122, 'perplexity': 1.2796559339132487, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 123, 'perplexity': 1.2794858554514263, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 124, 'perplexity': 1.279307793037508, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 125, 'perplexity': 1.2791217881320378, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 126, 'perplexity': 1.2789296737290354, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 127, 'perplexity': 1.2787315478624754, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 128, 'perplexity': 1.2785290136658587, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 129, 'perplexity': 1.2783223399224717, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 130, 'perplexity': 1.2781119666932896, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 131, 'perplexity': 1.277899266852315, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 132, 'perplexity': 1.2776839179101003, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 133, 'perplexity': 1.2774668920402883, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 134, 'perplexity': 1.2772485326944858, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 135, 'perplexity': 1.2770287073646525, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 136, 'perplexity': 1.276807968572205, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 137, 'perplexity': 1.2765858222159516, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 138, 'perplexity': 1.2763637525485958, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 139, 'perplexity': 1.2761419306875201, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 140, 'perplexity': 1.2759200333011727, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 141, 'perplexity': 1.275699562184457, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 142, 'perplexity': 1.2754793192250065, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 143, 'perplexity': 1.275261071583558, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 144, 'perplexity': 1.2750439442652823, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 145, 'perplexity': 1.2748284306175488, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 146, 'perplexity': 1.2746154794967413, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 147, 'perplexity': 1.2744038362837837, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 148, 'perplexity': 1.2741953041016771, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 149, 'perplexity': 1.2739887044316238, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 150, 'perplexity': 1.2737843780001668, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 151, 'perplexity': 1.2735828171485628, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 152, 'perplexity': 1.2733822369348522, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 153, 'perplexity': 1.2731850273673333, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 154, 'perplexity': 1.2729875638068684, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 155, 'perplexity': 1.2727923688678227, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 156, 'perplexity': 1.272597753791431, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 157, 'perplexity': 1.2724018412532299, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 158, 'perplexity': 1.2722087645654774, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 159, 'perplexity': 1.2720113955543282, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 160, 'perplexity': 1.271817468438486, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 161, 'perplexity': 1.2716197622116756, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 162, 'perplexity': 1.27142276876278, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 163, 'perplexity': 1.2712269234533873, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 164, 'perplexity': 1.2710244225655551, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 165, 'perplexity': 1.270832710039289, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 166, 'perplexity': 1.2706235693768666, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 167, 'perplexity': 1.270436706841978, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 168, 'perplexity': 1.2702215933745924, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 169, 'perplexity': 1.2700378558083474, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 170, 'perplexity': 1.2698213907386147, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 171, 'perplexity': 1.2696329434634361, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 172, 'perplexity': 1.2694306964896436, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 173, 'perplexity': 1.2692084908723873, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 174, 'perplexity': 1.2690669751756476, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 175, 'perplexity': 1.2687183877620916, 'learning_rate': 0.0003901844231062339}\n",
      "{'epoch': 176, 'perplexity': 1.2686953990316858, 'learning_rate': 0.0003901844231062339}\n",
      "update learning rate from 0.000 to 0.000\n",
      "{'epoch': 177, 'perplexity': 1.2676427876988061, 'learning_rate': 0.00026012294873748923}\n",
      "{'epoch': 178, 'perplexity': 1.2673541535245756, 'learning_rate': 0.00026012294873748923}\n",
      "{'epoch': 179, 'perplexity': 1.2670412291389976, 'learning_rate': 0.00026012294873748923}\n",
      "{'epoch': 180, 'perplexity': 1.2670791415204672, 'learning_rate': 0.00026012294873748923}\n",
      "update learning rate from 0.000 to 0.000\n",
      "{'epoch': 181, 'perplexity': 1.2667885215016756, 'learning_rate': 0.00017341529915832616}\n",
      "{'epoch': 182, 'perplexity': 1.266793202912075, 'learning_rate': 0.00017341529915832616}\n",
      "update learning rate from 0.000 to 0.000\n",
      "{'epoch': 183, 'perplexity': 1.2664599787893647, 'learning_rate': 0.00011561019943888411}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 184, 'perplexity': 1.2664292559948764, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 185, 'perplexity': 1.266379984076602, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 186, 'perplexity': 1.26634552695345, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 187, 'perplexity': 1.2662916919340972, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 188, 'perplexity': 1.2662465198352344, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 189, 'perplexity': 1.266188236245751, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 190, 'perplexity': 1.2661362568680525, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 191, 'perplexity': 1.2660754503080527, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 192, 'perplexity': 1.2660194195446484, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 193, 'perplexity': 1.2659572415060427, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 194, 'perplexity': 1.2658988769148243, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 195, 'perplexity': 1.265835818262213, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 196, 'perplexity': 1.2657758183148555, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 197, 'perplexity': 1.2657123319987098, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 198, 'perplexity': 1.2656514892187927, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 199, 'perplexity': 1.265587726257571, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 200, 'perplexity': 1.2655261540126777, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 201, 'perplexity': 1.2654621899403544, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 202, 'perplexity': 1.2654002278282916, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 203, 'perplexity': 1.2653360627159538, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 204, 'perplexity': 1.2652738805309658, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 205, 'perplexity': 1.2652095710006233, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 206, 'perplexity': 1.2651470745450264, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 207, 'perplexity': 1.265082959971834, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 208, 'perplexity': 1.2650203943692384, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 209, 'perplexity': 1.2649560977227279, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 210, 'perplexity': 1.2648935383941975, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 211, 'perplexity': 1.264829248195341, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 212, 'perplexity': 1.2647665255218263, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 213, 'perplexity': 1.2647023171607283, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 214, 'perplexity': 1.2646396384709004, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 215, 'perplexity': 1.2645754930824018, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 216, 'perplexity': 1.2645128018352705, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 217, 'perplexity': 1.264448530987947, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 218, 'perplexity': 1.2643859590798618, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 219, 'perplexity': 1.264321826558557, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 220, 'perplexity': 1.2642593174373022, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 221, 'perplexity': 1.2641952290155016, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 222, 'perplexity': 1.2641328391756128, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 223, 'perplexity': 1.2640687383292148, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 224, 'perplexity': 1.264006561918626, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 225, 'perplexity': 1.263942561646471, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 226, 'perplexity': 1.263880560941781, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 227, 'perplexity': 1.2638166047140855, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 228, 'perplexity': 1.2637547985021393, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 229, 'perplexity': 1.2636907356556473, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 230, 'perplexity': 1.263629236871905, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 231, 'perplexity': 1.2635652557047978, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 232, 'perplexity': 1.2635039324767343, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 233, 'perplexity': 1.2634400517877633, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 234, 'perplexity': 1.2633790170232686, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 235, 'perplexity': 1.2633149544012063, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 236, 'perplexity': 1.2632542268632079, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 237, 'perplexity': 1.2631903776219466, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 238, 'perplexity': 1.2631299948701733, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 239, 'perplexity': 1.2630659448753685, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 240, 'perplexity': 1.263005869195731, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 241, 'perplexity': 1.2629418066757128, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 242, 'perplexity': 1.2628820379950123, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 243, 'perplexity': 1.262817944121085, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 244, 'perplexity': 1.2627586893494847, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 245, 'perplexity': 1.2626943571327744, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 246, 'perplexity': 1.2626354656401109, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 247, 'perplexity': 1.2625710456322508, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 248, 'perplexity': 1.2625125549616827, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 249, 'perplexity': 1.2624479154814603, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 250, 'perplexity': 1.2623900136583528, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 251, 'perplexity': 1.262325154730785, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 252, 'perplexity': 1.262267634723079, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 253, 'perplexity': 1.2622024999588066, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 254, 'perplexity': 1.2621456626075889, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 255, 'perplexity': 1.2620802520402965, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 256, 'perplexity': 1.262023909140008, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 257, 'perplexity': 1.2619582792268313, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 258, 'perplexity': 1.2619024870822018, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 259, 'perplexity': 1.2618363746098191, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 260, 'perplexity': 1.2617812271227098, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 261, 'perplexity': 1.2617146321768353, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 262, 'perplexity': 1.26166026081846, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 263, 'perplexity': 1.2615931834776253, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 264, 'perplexity': 1.2615394564983997, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 265, 'perplexity': 1.2614719720374328, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 266, 'perplexity': 1.2614189268978537, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 267, 'perplexity': 1.2613509038121467, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 268, 'perplexity': 1.2612985403765915, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 269, 'perplexity': 1.2612300727317265, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 270, 'perplexity': 1.2611784660330458, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 271, 'perplexity': 1.2611093847702695, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 272, 'perplexity': 1.2610584782853966, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 273, 'perplexity': 1.2609890465810987, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 274, 'perplexity': 1.26093880258451, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 275, 'perplexity': 1.2608688701821702, 'learning_rate': 0.00011561019943888411}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 276, 'perplexity': 1.2608193073300005, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 277, 'perplexity': 1.2607488743160358, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 278, 'perplexity': 1.260699917329145, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 279, 'perplexity': 1.2606291904271951, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 280, 'perplexity': 1.2605808203953535, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 281, 'perplexity': 1.2605096118153216, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 282, 'perplexity': 1.2604617534948617, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 283, 'perplexity': 1.2603902511402765, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 284, 'perplexity': 1.260342810524138, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 285, 'perplexity': 1.2602712585783273, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 286, 'perplexity': 1.2602241980170468, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 287, 'perplexity': 1.2601523335835807, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 288, 'perplexity': 1.2601055403416246, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 289, 'perplexity': 1.2600337390025227, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 290, 'perplexity': 1.2599870252654166, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 291, 'perplexity': 1.2599153808729617, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 292, 'perplexity': 1.2598687278443137, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 293, 'perplexity': 1.2597971277232736, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 294, 'perplexity': 1.259750347671178, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 295, 'perplexity': 1.2596791109207481, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 296, 'perplexity': 1.2596322601710357, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 297, 'perplexity': 1.2595614242456765, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 298, 'perplexity': 1.2595142025084989, 'learning_rate': 0.00011561019943888411}\n",
      "{'epoch': 299, 'perplexity': 1.2594436922640684, 'learning_rate': 0.00011561019943888411}\n"
     ]
    }
   ],
   "source": [
    "epoch_log_loss = []\n",
    "import math\n",
    "for epoch in range(epochs):\n",
    "    dataiter = mx.io.NDArrayIter([inputs_train, queries_train], answers_train, batch_size, shuffle=False, last_batch_handle='discard')\n",
    "    \n",
    "    for batch in dataiter:\n",
    "        log_loss = []\n",
    "        train_loss = train(model, trainer, \n",
    "                           batch.data[0].as_in_context(ctx), \n",
    "                           batch.data[1].as_in_context(ctx),\n",
    "                           batch.label[0].as_in_context(ctx),\n",
    "                           batch_size)\n",
    "\n",
    "        # Logging\n",
    "        log_loss.append([train_loss])#, test_loss])\n",
    "    \n",
    "    epoch_log_loss.append([np.mean(log_loss)])\n",
    "    \n",
    "    state = { 'epoch': epoch, 'learning_rate': trainer.learning_rate, 'perplexity': math.exp(epoch_log_loss[epoch][0])}\n",
    "    print(state)\n",
    "    \n",
    "    lr_decay = 1.5\n",
    "    if (len(epoch_log_loss) > 1) and (epoch_log_loss[epoch][0] > epoch_log_loss[epoch-1][0] * 0.9999):\n",
    "        print ('update learning rate from %.3f to %.3f' % (trainer.learning_rate, trainer.learning_rate/lr_decay))\n",
    "        trainer.set_learning_rate(trainer.learning_rate / lr_decay)\n",
    "    if trainer.learning_rate < 1e-5: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ = model(mx.nd.array(inputs_test, mx.cpu()), mx.nd.array(queries_test, mx.cpu()))\n",
    "pred_ = pred_.asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2, 3, 5, 6, 10, 13}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([np.argmax(i) for i in pred_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2, 3, 5, 6, 10, 13}\n",
      "{2, 3, 5, 6, 10, 13}\n"
     ]
    }
   ],
   "source": [
    "print (set(np.argmax(i) for i in pred_))\n",
    "print (set(i for i in answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 2, 10, 10, 10, 6, 5, 6, 5, 13]\n",
      "[6, 2, 10, 6, 10, 6, 5, 6, 13, 13]\n"
     ]
    }
   ],
   "source": [
    "print ([np.argmax(i) for i in pred_[0:10]])\n",
    "print ([i for i in answers_test[0:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70699999999999996"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum([bool(np.argmax(i) == answers_test[idx:idx+1]) for idx, i in enumerate(pred_)])/len(pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "## base rate\n",
    "print (1/len(set(i for i in answers_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "john travelled to the hallway mary\n",
      "mary journeyed to the bathroom kitchen\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "where is john\n",
      "hallway\n"
     ]
    }
   ],
   "source": [
    "for ido in test_data.data_story[idx:idx+1][0]:\n",
    "    print (\" \".join([word_re.get(int(i), '.') for i in ido if int(i) != 0]))\n",
    "    \n",
    "print (\" \".join([word_re.get(int(i), '.') for i in test_data.data_query[idx:idx+1][0] if int(i) != 0]))\n",
    "print (word_re.get(int(test_data.data_answer[idx:idx+1][0]), '.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hallway\n"
     ]
    }
   ],
   "source": [
    "print (word_re[ np.argmax(pred_[idx])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
